# Flight Delay Classification Project ‚úàÔ∏è

## Project Description

This project focuses on building and evaluating multiple machine learning classification models to predict **flight delays** based on historical flight data. It involves data cleaning, feature engineering, exploratory analysis, model training, and performance evaluation using metrics such as accuracy, precision, recall, and F1-score.

##  Installation Instructions

To run this project locally:

1. Clone the repository:
   `git clone https://github.com/your-username/flight-delay-classification.git`  
   `cd flight-delay-classification`

2. Open the following Jupyter notebooks in your IDE or Jupyter environment:
   - `Task1.ipynb` ‚Äì Data cleaning and exploration
   - `Task2.ipynb` ‚Äì Feature engineering
   - `Task3.ipynb` ‚Äì Model training
   - `Task4.ipynb` ‚Äì Results analysis

##  Task Breakdown

###  Task 1: Data Cleaning & Exploration
- Loaded raw flight data.
- Cleaned null values and irrelevant columns.
- Explored key features using visualizations and descriptive stats.
- Saved cleaned data as `Cleaned_Flight_data.csv`.

###  Task 2: Feature Engineering
- Encoded categorical variables (e.g., Airline, Source).
- Extracted date/time-based features.
- Scaled/standardized numerical columns.
- Output saved as `feature_engineered_data.csv`.

###  Task 3: Model Building & Training
- Trained and evaluated:
  - Logistic Regression
  - Decision Tree
  - Random Forest
  - Support Vector Machine
- Evaluated using Accuracy, Precision, Recall, F1-Score.
- Results saved to `classification_model_results.csv`.

###  Task 4: Results Analysis
- Loaded and compared model results.
- Random Forest identified as best with 98.5% accuracy.
- Visualized performance metrics (optional in notebook).
- Summarized findings and potential improvements.


##  Data Sources

- `Flight_Data.csv` ‚Äì Original flight dataset  
- `Cleaned_Flight_data.csv` ‚Äì Preprocessed dataset  
- `feature_engineered_data.csv` ‚Äì Dataset after feature engineering  
- `classification_model_results.csv` ‚Äì Summary of model performances

##  Code Structure

‚îú‚îÄ‚îÄ Task1.ipynb                  # Data cleaning and exploration <br>
‚îú‚îÄ‚îÄ Task2.ipynb                  # Feature engineering <br>
‚îú‚îÄ‚îÄ Task3.ipynb                  # Model training  <br>
‚îú‚îÄ‚îÄ Task4.ipynb                  # Evaluation and visualization  <br>
‚îú‚îÄ‚îÄ feature_engineered_data.csv # Processed data after feature engineering  <br>
‚îú‚îÄ‚îÄ classification_model_results.csv # Model prediction results  <br>
‚îú‚îÄ‚îÄ README.md                    # Project documentation   <br>




## üìä Results and Evaluation
 ______________________________________________________________________
| Model                    | Accuracy | Precision | Recall | F1 Score |
|--------------------------|----------|-----------|--------|----------|
| Logistic Regression      | 80.3%    | 83.6%     | 88.9%  | 86.2%    |
| Decision Tree            | 96.7%    | 97.1%     | 98.1%  | 97.6%    |
| **Random Forest**        | **98.5%**| **99.8%** | 98.1%  | **98.9%**|
| Support Vector Machine   | 80.2%    | 83.9%     | 88.1%  | 86.0%    |
_______________________________________________________________________

‚úÖ **Random Forest** achieved the highest performance and is the most accurate model for this task.

##  Future Work

- Tune hyperparameters using GridSearchCV for better model optimization.
- Incorporate real-time weather and air traffic data to enhance predictive accuracy.
- Deploy the best-performing model via a web dashboard (e.g., using Flask or Streamlit).
- Explore deep learning alternatives for further improvement.

